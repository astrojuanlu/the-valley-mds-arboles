{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R53FGLN8jo1L"
   },
   "source": [
    "# 01 INTRO: Árboles de Decisión\n",
    "Explicación de cómo construír árboles de decisión.\n",
    "\n",
    "Notebook original por [Javier Blanco Cordero](https://www.linkedin.com/in/javier-blanco-cordero-71373656/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSuEDXhPLi8u"
   },
   "source": [
    "## 0101 Qué es un árbol de decisión?\n",
    "Un tipo de algoritmo de aprendizaje supervisado que se basa en realizar particiones a partir de distintos niveles de las variables disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnHRaho3rsXS"
   },
   "source": [
    "## 0102 Import\n",
    "Importamos todas las librerías necesarias para este análisis ([¿No sabes lo que es una librería de Python?](https://www.quora.com/What-is-a-Python-library-and-what-can-I-use-it-for)): pandas, numpy, seaborn, matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4be6xiUqjPHI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AblkT14d4Gvt"
   },
   "source": [
    "## 0103 Carga el dataset de coches de segunda mano\n",
    "Para probar a hacer árboles de decisión sin overfitting utilizaremos un dataset sobre el precio de distintos coches de segunda mano que he encontrado en Kaggle ([aquí](https://www.kaggle.com/harturo123/online-adds-of-used-cars)).\n",
    "\n",
    "Podéis encontrar el archivo listo para importar en mi github: 'https://raw.githubusercontent.com/astrojuanlu/the-valley-mds-arboles/main/data/coches_usados_esp.csv'.\n",
    "\n",
    "Importa este dataset en un dataframe llamado **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMZACcIXOclu"
   },
   "outputs": [],
   "source": [
    "# Url archivo raw\n",
    "url = \"https://raw.githubusercontent.com/astrojuanlu/the-valley-mds-arboles/main/data/coches_usados_esp.csv\"\n",
    "\n",
    "# Importa csv\n",
    "df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Visualización primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBOQJ0AjdYrM"
   },
   "source": [
    "# 02 EDA\n",
    "Realizaremos un pequeño análisis exploratorio visual para familiarizarnos con el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGrwhGyaj0-a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1_5T47haV8Q"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LoZpl8rjWEX"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUz-qSwBjaEW"
   },
   "outputs": [],
   "source": [
    "# Visualización coeficientes Pearson\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(np.round(df.corr(), 2), vmin=-1, vmax=1, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgH2I3otagdU"
   },
   "source": [
    "# 03 EJEMPLO\n",
    "Vamos a ver paso a paso cómo realizar un modelo que prediga el precio sin caer en overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCQnyHTcawdU"
   },
   "source": [
    "## 0301 Preparamos los datos\n",
    "El dataframe tiene algunos nulos, así como variables categóricas y presencia de ciertas variables que probablemente no queramos usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAXljoaabIQ5"
   },
   "source": [
    "### 030101 Variables Útiles\n",
    "De entre las variables disponibles, veamos cuáles queremos utilizar como predictoras para el estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koTejjQJbTmp"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSe15ngNbRsI"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CduKZ0_bntL"
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"make\",\n",
    "    \"model\",\n",
    "    \"months_old\",\n",
    "    \"power\",\n",
    "    \"sale_type\",\n",
    "    \"num_owners\",\n",
    "    \"gear_type\",\n",
    "    \"fuel_type\",\n",
    "    \"kms\",\n",
    "    \"price\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mByQxiFCbRJY"
   },
   "source": [
    "### 030102 Dumificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1_P8ceTb_Cy"
   },
   "outputs": [],
   "source": [
    "df_i = pd.get_dummies(\n",
    "    df[cols],\n",
    "    prefix_sep=\"_\",\n",
    "    drop_first=True,\n",
    "    columns=[\"make\", \"model\", \"sale_type\", \"gear_type\", \"fuel_type\"],\n",
    ")\n",
    "\n",
    "display(len(df_i))\n",
    "df_i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eu6b-OOdCYC"
   },
   "source": [
    "### 030103 Limpieza de nulos\n",
    "Con la dumificación hemos eliminado los nulos en las columnas categóricas sin deshacernos de las filas. Queda algún nulo en las variables numéricas?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTdhLHmVdVDi"
   },
   "outputs": [],
   "source": [
    "df_i.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKE3Tr5tcx1R"
   },
   "outputs": [],
   "source": [
    "df_i[[\"months_old\", \"power\", \"num_owners\", \"kms\", \"price\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKQcxVgWeFna"
   },
   "outputs": [],
   "source": [
    "# Hay muchos nulos en num_owners\n",
    "# Quizás esto tiene que ver con origenes del coche desconocidos?\n",
    "# Vamos a limpiar la variable en 1, 2, 3+, nulo y la utilizamos como categórica\n",
    "filtro_muchos_owners = df_i[\"num_owners\"] >= 3\n",
    "df_i.loc[filtro_muchos_owners, \"num_owners\"] = \"3+\"\n",
    "df_i = pd.get_dummies(\n",
    "    df_i, prefix_sep=\"_\", dummy_na=True, drop_first=True, columns=[\"num_owners\"]\n",
    ")\n",
    "df_i.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wa3pvtGgP9D"
   },
   "outputs": [],
   "source": [
    "df_i[[\"months_old\", \"power\", \"kms\", \"price\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6fBmkLdhUH7"
   },
   "outputs": [],
   "source": [
    "for col in [\"months_old\", \"power\", \"kms\"]:\n",
    "    df_i[col] = df_i[col].fillna(df_i[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFtfx3TXhfKR"
   },
   "outputs": [],
   "source": [
    "df_i.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NQpz3yMhlP8"
   },
   "source": [
    "##0302 Train - test split\n",
    "Separamos el set de datos en dos utilizando [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RY1xSE0ibVy"
   },
   "outputs": [],
   "source": [
    "X = df_i.drop(\"price\", axis=1)\n",
    "y = df_i[\"price\"]\n",
    "\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABXKI_CniEME"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGzX2Ku3jQv5"
   },
   "source": [
    "## 0303 Entrenamos el árbol de decisión\n",
    "Sobre el set de entrenamiento, comprobamos el modelo sobre el set de test.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y12bT7TSj9gq"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=10)\n",
    "# Entreno el árbol con el set de entrenamiento\n",
    "modelo = modelo.fit(X=X_train, y=y_train)\n",
    "# Uso el árbol para predecir sobre el dataset de entrenamiento\n",
    "y_pred_train = modelo.predict(X_train)\n",
    "# Uso el árbol para predecir sobre el dataset de test\n",
    "y_pred_test = modelo.predict(X_test)\n",
    "# Cómo de buena es la predicción?\n",
    "print(\n",
    "    \"RMSE en set de entrenamiento :\",\n",
    "    mean_squared_error(y_train, y_pred_train, squared=False),\n",
    ")\n",
    "print(\"RMSE en set de test :\", mean_squared_error(y_test, y_pred_test, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-eKMEkpltgt"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=5)\n",
    "# Entreno el árbol con el set de entrenamiento\n",
    "modelo = modelo.fit(X=X_train, y=y_train)\n",
    "# Uso el árbol para predecir sobre el dataset de entrenamiento\n",
    "y_pred_train = modelo.predict(X_train)\n",
    "# Uso el árbol para predecir sobre el dataset de test\n",
    "y_pred_test = modelo.predict(X_test)\n",
    "# Cómo de buena es la predicción?\n",
    "print(\n",
    "    \"RMSE en set de entrenamiento :\",\n",
    "    mean_squared_error(y_train, y_pred_train, squared=False),\n",
    ")\n",
    "print(\"RMSE en set de test :\", mean_squared_error(y_test, y_pred_test, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt-I-N3Glwwp"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=50)\n",
    "# Entreno el árbol con el set de entrenamiento\n",
    "modelo = modelo.fit(X=X_train, y=y_train)\n",
    "# Uso el árbol para predecir sobre el dataset de entrenamiento\n",
    "y_pred_train = modelo.predict(X_train)\n",
    "# Uso el árbol para predecir sobre el dataset de test\n",
    "y_pred_test = modelo.predict(X_test)\n",
    "# Cómo de buena es la predicción?\n",
    "print(\n",
    "    \"RMSE en set de entrenamiento :\",\n",
    "    mean_squared_error(y_train, y_pred_train, squared=False),\n",
    ")\n",
    "print(\"RMSE en set de test :\", mean_squared_error(y_test, y_pred_test, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orWBwiPxm5Oi"
   },
   "outputs": [],
   "source": [
    "def entrenar_modelo_y_predecir(modelo):\n",
    "    # Entreno el árbol con el set de entrenamiento\n",
    "    modelo = modelo.fit(X=X_train, y=y_train)\n",
    "    # Uso el árbol para predecir sobre el dataset de entrenamiento\n",
    "    y_pred_train = modelo.predict(X_train)\n",
    "    # Uso el árbol para predecir sobre el dataset de test\n",
    "    y_pred_test = modelo.predict(X_test)\n",
    "    # Cómo de buena es la predicción?\n",
    "    print(\n",
    "        \"RMSE en set de entrenamiento :\",\n",
    "        mean_squared_error(y_train, y_pred_train, squared=False),\n",
    "    )\n",
    "    print(\n",
    "        \"RMSE en set de test :\", mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MY1urTMJnI7S"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=25)\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psH9u3Gkl4hr"
   },
   "source": [
    "## 0304 Probamos medidas contra el overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOKrcoHimAjh"
   },
   "source": [
    "### 030401 min_samples_split\n",
    "Tamaño muestral mínimo para permitir una partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbyvemCimZ7Z"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=10, min_samples_split=20)\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHtM6hxVmpvS"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=15, min_samples_split=20)\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PM_oDEfWmuzL"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(max_depth=15, min_samples_split=25)\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WHNSaNfmzDL"
   },
   "source": [
    "### 030402 min_samples_leaf\n",
    "Tamaño muestral mínimo en una hoja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzpo8en2nx8j"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(\n",
    "    max_depth=15, min_samples_split=25, min_samples_leaf=10\n",
    ")\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvKhW2ANoG_T"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(\n",
    "    max_depth=20, min_samples_split=20, min_samples_leaf=2\n",
    ")\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffxLpFnZo0zF"
   },
   "source": [
    "### 030402 min_samples_leaf\n",
    "Mínimo descenso de impuridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FADakO2_pHsi"
   },
   "outputs": [],
   "source": [
    "# Inicializo un árbol\n",
    "modelo = tree.DecisionTreeRegressor(\n",
    "    max_depth=15, min_samples_split=25, min_impurity_decrease=0.25\n",
    ")\n",
    "# Entrenamos y predecimos con dicho modelo\n",
    "entrenar_modelo_y_predecir(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V66-xgckYMQs"
   },
   "source": [
    "# 06 EJERCICIO TITANIC\n",
    "Recordais el dataset del Titanic?\n",
    "\n",
    "Vamos a resolver este problema teniendo en cuenta todo lo que sabemos ya. El objetivo es crear una árbol de decisión que prediga si un pasajero falleció o no (pasajeros cuyos datos no conocemos todavía).\n",
    "\n",
    "Toma las medidas oportunas para que tu modelo sea lo más preciso posible sin caer en overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDiMGl7xOm6o"
   },
   "source": [
    "## 0601 Importa el dataset\n",
    "Puedes encontrarlo en mi github. Este es el link al archivo raw: https://raw.githubusercontent.com/astrojuanlu/the-valley-mds-arboles/main/data/titanic.csv.\n",
    "\n",
    "Importa los datos en un dataframe llamado dataframe **df_titanic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYiZbvGgYGzt"
   },
   "outputs": [],
   "source": [
    "# Url archivo raw\n",
    "url = \"https://raw.githubusercontent.com/astrojuanlu/the-valley-mds-arboles/main/data/titanic.csv\"\n",
    "\n",
    "# Importa csv\n",
    "df_titanic = pd.read_csv(url)\n",
    "\n",
    "# Visualización primeras filas\n",
    "df_titanic.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60P6G1BxzWBD"
   },
   "outputs": [],
   "source": [
    "df_titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS0_ouF8qiVz"
   },
   "source": [
    "## 0602 Prepara los datos\n",
    "Quédate con las variables interesantes, dumifica las categóricas y limpia los nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58IzhBMiqgNK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvI6ugAjqyAT"
   },
   "source": [
    "## 0603 Train - test split\n",
    "Utiliza una partición del 30% para tu set de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1-gJw0gq9sY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgZiyRv7q_09"
   },
   "source": [
    "## 0404 Entrena varios árboles\n",
    "Entrena varios árboles de decisión controlando los distintos parámetros para buscar el punto óptimo entre bias y varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rW5nSkdUrJzA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
